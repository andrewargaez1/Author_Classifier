{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut, KFold\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_it(item):\n",
    "    f=codecs.open(item ,'r')\n",
    "    f=f.read()\n",
    "    f=f.replace(\"\\n\", \" \")\n",
    "    sent_tokens = sent_tokenize(f)\n",
    "    tokens = [sent for sent in map(word_tokenize, sent_tokens)]\n",
    "    list(enumerate(tokens))\n",
    "    others = '“,”,’,—'\n",
    "    stopwords_ = set(stopwords.words('english'))\n",
    "    tokens_lower = [[word.lower() for word in sent] for sent in tokens]\n",
    "    punctuation_ = set(string.punctuation)\n",
    "    clean_token= [[word.replace(str(punctuation_),'') for word in sent] for sent in tokens_lower]\n",
    "\n",
    "    def filter_tokens(sent):\n",
    "        return([w for w in sent if not w in stopwords_ and not w in punctuation_ and not w in others])\n",
    "\n",
    "    tokens_filtered = list(map(filter_tokens, clean_token))\n",
    "\n",
    "\n",
    "\n",
    "    return tokens_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(x, y = 30):\n",
    "    l=len(x)\n",
    "    v=l//y\n",
    "    remainder=y\n",
    "    all_series = []\n",
    "    for loops in range(v+1):\n",
    "        new_elem = []\n",
    "        if loops > (v - 1):\n",
    "            remainder = l%y\n",
    "        if remainder > 0:\n",
    "            for i in range(remainder):\n",
    "                temp = (y * (loops)) + i\n",
    "                new_elem.extend(x[temp])\n",
    "            all_series.append(new_elem)\n",
    "    return np.array(all_series,dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_it_df(item,title,author):\n",
    "    df = pd.DataFrame()\n",
    "    df['txt']= chunk(read_it(item))\n",
    "    df['title']= title\n",
    "    df['author'] = author\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "bell = make_it_df(\"/Users/andrewargaez/Author_Classifier/WBT.txt\",'For Whom the Bell Tolls','Ernest Hemmingway')\n",
    "fta = make_it_df(\"/Users/andrewargaez/Author_Classifier/FTA.txt\", \"A Farewell to Arms\", \"Ernest Hemingway\")\n",
    "\n",
    "kar = make_it_df(\"/Users/andrewargaez/Author_Classifier/karmaz.txt\", \"The Brothers Karmazov\", \"Fyodor Dostoevsky\")\n",
    "cp = make_it_df(\"/Users/andrewargaez/Author_Classifier/CP.txt\", \"Crime and Punishment\", \"Fyodor Dostoevsky\")\n",
    "\n",
    "# gg = make_it_df(\"/Users/andrewargaez/Author_Classifier/GG.txt\", \"The Great Gatsby\", \"F. Scott Fitzgerald\")\n",
    "# sop = make_it_df(\"/Users/andrewargaez/Author_Classifier/sop.txt\", \"This Side of Paradise\", \"F. Scott Fitzgerald\")\n",
    "\n",
    "# pp = make_it_df(\"/Users/andrewargaez/Author_Classifier/PP.txt\", \"Pride and Prejudice\", \"Jane Austen\")\n",
    "# em = make_it_df(\"/Users/andrewargaez/Author_Classifier/emma.txt\", \"Emma\", \"Jane Austen\")\n",
    "\n",
    "# al= make_it_df(\"/Users/andrewargaez/Author_Classifier/alice.txt\", \"Alice in Woderland\", \"Lewis Carrol\")\n",
    "# tlg= make_it_df(\"/Users/andrewargaez/Author_Classifier/tlg.txt\", \"Through the Looking Glass\", \"Lewis Carrol\")\n",
    "\n",
    "# drac= make_it_df(\"/Users/andrewargaez/Author_Classifier/drac.txt\", \"Dracula\", \"Bram Stoker\")\n",
    "# lf= make_it_df(\"/Users/andrewargaez/Author_Classifier/LF.txt\", \"Lord of the Flies\", \"William Golding\")\n",
    "# pet = make_it_df(\"/Users/andrewargaez/Author_Classifier/Peter.txt\", \"Peter Pan\", \"J. M. Barrie\")\n",
    "\n",
    "# pdg = make_it_df(\"/Users/andrewargaez/Author_Classifier/pdg.txt\", \"Picture of Dorian Gray\", \"Oscar Wilde\")\n",
    "\n",
    "# ti  = make_it_df(\"/Users/andrewargaez/Author_Classifier/TI.txt\", \"Treasure Island\", \"Robert Louis Stevenson\")\n",
    "\n",
    "# huck = make_it_df(\"/Users/andrewargaez/Author_Classifier/huck.txt\", \"Adventures of Huckleberry Fin\", \"Mark Twain\")\n",
    "# ts = make_it_df(\"/Users/andrewargaez/Author_Classifier/ts.txt\", \"Adventures of Tom Sawyer\", \"Mark Twain\")\n",
    "\n",
    "# wow = make_it_df(\"/Users/andrewargaez/Author_Classifier/wow.txt\", \"The War of the Worlds\", \"H. G. Wells\")\n",
    "# im = make_it_df(\"/Users/andrewargaez/Author_Classifier/IM.txt\", \"The Invisible Man\", \"H. G. Wells\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[lay, flat, brown, pine-needled, floor, forest...</td>\n",
       "      <td>For Whom the Bell Tolls</td>\n",
       "      <td>Ernest Hemmingway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[hungry, yes, young, man, said, eat, later, ca...</td>\n",
       "      <td>For Whom the Bell Tolls</td>\n",
       "      <td>Ernest Hemmingway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[young, man, whose, name, robert, jordan, extr...</td>\n",
       "      <td>For Whom the Bell Tolls</td>\n",
       "      <td>Ernest Hemmingway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[never, attacks, golz, said, make, mine, artil...</td>\n",
       "      <td>For Whom the Bell Tolls</td>\n",
       "      <td>Ernest Hemmingway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[see, people, mountains, get, many, men, need,...</td>\n",
       "      <td>For Whom the Bell Tolls</td>\n",
       "      <td>Ernest Hemmingway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>[want, buried, churchyard, snegiryov, wailed, ...</td>\n",
       "      <td>The Brothers Karmazov</td>\n",
       "      <td>Fyodor Dostoevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>[one, moment, went, coffin, set, straight, cov...</td>\n",
       "      <td>The Brothers Karmazov</td>\n",
       "      <td>Fyodor Dostoevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>[half‐way, snegiryov, suddenly, stopped, stood...</td>\n",
       "      <td>The Brothers Karmazov</td>\n",
       "      <td>Fyodor Dostoevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>[serious, earnest, expression, looked, one, an...</td>\n",
       "      <td>The Brothers Karmazov</td>\n",
       "      <td>Fyodor Dostoevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>[dear, boys, day, forth, place, heart, beg, ke...</td>\n",
       "      <td>The Brothers Karmazov</td>\n",
       "      <td>Fyodor Dostoevsky</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1043 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    txt  \\\n",
       "0     [lay, flat, brown, pine-needled, floor, forest...   \n",
       "1     [hungry, yes, young, man, said, eat, later, ca...   \n",
       "2     [young, man, whose, name, robert, jordan, extr...   \n",
       "3     [never, attacks, golz, said, make, mine, artil...   \n",
       "4     [see, people, mountains, get, many, men, need,...   \n",
       "...                                                 ...   \n",
       "1038  [want, buried, churchyard, snegiryov, wailed, ...   \n",
       "1039  [one, moment, went, coffin, set, straight, cov...   \n",
       "1040  [half‐way, snegiryov, suddenly, stopped, stood...   \n",
       "1041  [serious, earnest, expression, looked, one, an...   \n",
       "1042  [dear, boys, day, forth, place, heart, beg, ke...   \n",
       "\n",
       "                        title             author  \n",
       "0     For Whom the Bell Tolls  Ernest Hemmingway  \n",
       "1     For Whom the Bell Tolls  Ernest Hemmingway  \n",
       "2     For Whom the Bell Tolls  Ernest Hemmingway  \n",
       "3     For Whom the Bell Tolls  Ernest Hemmingway  \n",
       "4     For Whom the Bell Tolls  Ernest Hemmingway  \n",
       "...                       ...                ...  \n",
       "1038    The Brothers Karmazov  Fyodor Dostoevsky  \n",
       "1039    The Brothers Karmazov  Fyodor Dostoevsky  \n",
       "1040    The Brothers Karmazov  Fyodor Dostoevsky  \n",
       "1041    The Brothers Karmazov  Fyodor Dostoevsky  \n",
       "1042    The Brothers Karmazov  Fyodor Dostoevsky  \n",
       "\n",
       "[1043 rows x 3 columns]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df =pd.concat([bell, kar],ignore_index=True)\n",
    "test= pd.concat([fta, cp],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeaky_clean(new_df):\n",
    "    others = '“,”,’,—,_,.,——,--'\n",
    "    vals = list(new_df['txt'].values)\n",
    "    arr=[]\n",
    "\n",
    "    for _sent in vals:\n",
    "        sent=[]\n",
    "        for word in _sent:\n",
    "            for char in others:\n",
    "                word = word.replace(char,'')\n",
    "            sent.append(word)      \n",
    "        arr.append(sent)\n",
    "    return pd.Series(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[lay, flat, brown, pineneedled, floor, forest,...</td>\n",
       "      <td>For Whom the Bell Tolls</td>\n",
       "      <td>Ernest Hemmingway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[hungry, yes, young, man, said, eat, later, ca...</td>\n",
       "      <td>For Whom the Bell Tolls</td>\n",
       "      <td>Ernest Hemmingway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[young, man, whose, name, robert, jordan, extr...</td>\n",
       "      <td>For Whom the Bell Tolls</td>\n",
       "      <td>Ernest Hemmingway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[never, attacks, golz, said, make, mine, artil...</td>\n",
       "      <td>For Whom the Bell Tolls</td>\n",
       "      <td>Ernest Hemmingway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[see, people, mountains, get, many, men, need,...</td>\n",
       "      <td>For Whom the Bell Tolls</td>\n",
       "      <td>Ernest Hemmingway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>[want, buried, churchyard, snegiryov, wailed, ...</td>\n",
       "      <td>The Brothers Karmazov</td>\n",
       "      <td>Fyodor Dostoevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>[one, moment, went, coffin, set, straight, cov...</td>\n",
       "      <td>The Brothers Karmazov</td>\n",
       "      <td>Fyodor Dostoevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>[half‐way, snegiryov, suddenly, stopped, stood...</td>\n",
       "      <td>The Brothers Karmazov</td>\n",
       "      <td>Fyodor Dostoevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>[serious, earnest, expression, looked, one, an...</td>\n",
       "      <td>The Brothers Karmazov</td>\n",
       "      <td>Fyodor Dostoevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>[dear, boys, day, forth, place, heart, beg, ke...</td>\n",
       "      <td>The Brothers Karmazov</td>\n",
       "      <td>Fyodor Dostoevsky</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1043 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    txt  \\\n",
       "0     [lay, flat, brown, pineneedled, floor, forest,...   \n",
       "1     [hungry, yes, young, man, said, eat, later, ca...   \n",
       "2     [young, man, whose, name, robert, jordan, extr...   \n",
       "3     [never, attacks, golz, said, make, mine, artil...   \n",
       "4     [see, people, mountains, get, many, men, need,...   \n",
       "...                                                 ...   \n",
       "1038  [want, buried, churchyard, snegiryov, wailed, ...   \n",
       "1039  [one, moment, went, coffin, set, straight, cov...   \n",
       "1040  [half‐way, snegiryov, suddenly, stopped, stood...   \n",
       "1041  [serious, earnest, expression, looked, one, an...   \n",
       "1042  [dear, boys, day, forth, place, heart, beg, ke...   \n",
       "\n",
       "                        title             author  \n",
       "0     For Whom the Bell Tolls  Ernest Hemmingway  \n",
       "1     For Whom the Bell Tolls  Ernest Hemmingway  \n",
       "2     For Whom the Bell Tolls  Ernest Hemmingway  \n",
       "3     For Whom the Bell Tolls  Ernest Hemmingway  \n",
       "4     For Whom the Bell Tolls  Ernest Hemmingway  \n",
       "...                       ...                ...  \n",
       "1038    The Brothers Karmazov  Fyodor Dostoevsky  \n",
       "1039    The Brothers Karmazov  Fyodor Dostoevsky  \n",
       "1040    The Brothers Karmazov  Fyodor Dostoevsky  \n",
       "1041    The Brothers Karmazov  Fyodor Dostoevsky  \n",
       "1042    The Brothers Karmazov  Fyodor Dostoevsky  \n",
       "\n",
       "[1043 rows x 3 columns]"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['txt']= squeaky_clean(new_df)\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['txt']= squeaky_clean(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(item):\n",
    "    data=[]\n",
    "    for row in item.txt:\n",
    "        data.append(' '.join(row))\n",
    "    labels = item.author\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(labels)\n",
    "    return data, np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(data):\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X = tfidf.fit_transform(data).toarray()\n",
    "    return X,tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,y =get_data(new_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, y_train, y_test = train_test_split(data, y, test_size=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, tf = vectorizer(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_y =get_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfidf = tf.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(522, 12053)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=tf.transform(data_test)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model  = RandomForestClassifier()\n",
    "#start = time.time()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(522,)"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hat= model.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5182341650671785"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, np.ones(len(y_test)))\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9984544049459042"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(_test, test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [261, 782]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-193-749634b799a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#trained = time.time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#tested = time.time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    498\u001b[0m         \"\"\"\n\u001b[1;32m    499\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    263\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [261, 782]"
     ]
    }
   ],
   "source": [
    "model  = RandomForestClassifier()\n",
    "#start = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "#y_hat = model.predict(X_test.T)\n",
    "#trained = time.time()\n",
    "score = model.score(X_test,y_test)\n",
    "#tested = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_naive_bayes(data, y):\n",
    "    print(\"tuning naive bayes...\")\n",
    "    kfold = KFold(5)\n",
    "    alphas = np.concatenate((np.arange(0, 0.1, 0.02), np.arange(.1, 1.3, 0.1)))\n",
    "    scores = defaultdict(list)\n",
    "    for train_index, test_index in kfold.split(data):\n",
    "        data_train, data_test = data[train_index], data[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        tfidf = TfidfVectorizer()\n",
    "        X_train = tfidf.fit_transform(data_train)\n",
    "        print(X_train.shape)\n",
    "        X_test = tfidf.transform(data_test)\n",
    "        for alpha in alphas:\n",
    "            nb = MultinomialNB(alpha=alpha)\n",
    "            nb.fit(X_train, y_train)\n",
    "            scores[alpha].append(nb.score(X_test, y_test))\n",
    "\n",
    "    print(\"alpha  score\")\n",
    "    for alpha in alphas:\n",
    "        print(\" %.2f  %f\" % (alpha, np.average(scores[alpha])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(data, y,t,t2):\n",
    "    data_train, data_test, y_train, y_test = train_test_split(data, y)\n",
    "    \n",
    "\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_train = tfidf.fit_transform(data_train).toarray()\n",
    "    X_test = tfidf.transform(data_test).toarray()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\"running models...\")\n",
    "    models = [(\"Random Forest\", RandomForestClassifier()),\n",
    "              (\"Decision Tree\", DecisionTreeClassifier()),\n",
    "              (\"kNN\", KNeighborsClassifier()),  \n",
    "              (\"Naive Bayes\", MultinomialNB()),\n",
    "              #(\"SVM\", OneVsRestClassifier(SVC())),\n",
    "              (\"Logistic\", OneVsRestClassifier(LogisticRegression()))]\n",
    "\n",
    "    print(\"%20s %7s %9s %9s\" % (\"Name\", \"Score\", \"TrainTime\", \"TestTime\"))\n",
    "\n",
    "    for name, model in models:\n",
    "        start = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_hat = model.predict(X_test.T)\n",
    "        trained = time.time()\n",
    "        score = model.score(y_hat,y_test)\n",
    "        tested = time.time()\n",
    "\n",
    "        # Silly stuff to make it print nicely\n",
    "        print(\"%20s   %.3f %9s %9s\" % (name, score,\n",
    "                                       str(round(trained - start, 2)),\n",
    "                                       str(round(tested - trained, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1043"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t, t2 = get_data(new_df)\n",
    "t = vectorizer(t)\n",
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397\n",
      "tuning naive bayes...\n",
      "(507, 10681)\n",
      "(507, 10709)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewargaez/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "/Users/andrewargaez/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(507, 10410)\n",
      "(507, 10495)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewargaez/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "/Users/andrewargaez/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(508, 10723)\n",
      "alpha  score\n",
      " 0.00  0.911811\n",
      " 0.02  0.988976\n",
      " 0.04  0.990551\n",
      " 0.06  0.990551\n",
      " 0.08  0.985814\n",
      " 0.10  0.984239\n",
      " 0.20  0.935421\n",
      " 0.30  0.892901\n",
      " 0.40  0.847232\n",
      " 0.50  0.803137\n",
      " 0.60  0.749594\n",
      " 0.70  0.713373\n",
      " 0.80  0.688176\n",
      " 0.90  0.675578\n",
      " 1.00  0.661405\n",
      " 1.10  0.645657\n",
      " 1.20  0.642507\n",
      "running models...\n",
      "                Name   Score TrainTime  TestTime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewargaez/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 159 features, but DecisionTreeClassifier is expecting 10437 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-da4f3f27a855>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtune_naive_bayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrun_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-134-e79bc3639183>\u001b[0m in \u001b[0;36mrun_models\u001b[0;34m(data, y, t, t2)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mtrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[0;32m--> 630\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;34m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n\u001b[0m\u001b[1;32m    403\u001b[0m                                     reset=False)\n\u001b[1;32m    404\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ensure_2d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    366\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n",
      "\u001b[0;31mValueError\u001b[0m: X has 159 features, but DecisionTreeClassifier is expecting 10437 features as input."
     ]
    }
   ],
   "source": [
    "test1, test2 = get_data(test)\n",
    "print(sum(test2))\n",
    "tune_naive_bayes(test1, test2)\n",
    "run_models(test1,test2,t,t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data, y = get_data(new_df)\n",
    "#tune_naive_bayes(data, y)\n",
    "#run_models(data, y,test1,test2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac68491ccfc62e6527a0fd75ffbc7adaab0e7c919453393b4b19032642ccd799"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}