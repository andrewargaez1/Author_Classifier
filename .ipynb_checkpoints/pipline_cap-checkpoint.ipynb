{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut, KFold\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.svm import SVC\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_it(item):\n",
    "    f=codecs.open(item ,'r')\n",
    "    f=f.read()\n",
    "    f=f.replace(\"\\n\", \" \")\n",
    "    sent_tokens = sent_tokenize(f)\n",
    "    tokens = [sent for sent in map(word_tokenize, sent_tokens)]\n",
    "    list(enumerate(tokens))\n",
    "    others = '“,”,’,—'\n",
    "    stopwords_ = set(stopwords.words('english'))\n",
    "    tokens_lower = [[word.lower() for word in sent] for sent in tokens]\n",
    "    punctuation_ = set(string.punctuation)\n",
    "    clean_token= [[word.replace(str(punctuation_),'') for word in sent] for sent in tokens_lower]\n",
    "\n",
    "    def filter_tokens(sent):\n",
    "        return([w for w in sent if not w in stopwords_ and not w in punctuation_ and not w in others])\n",
    "\n",
    "    tokens_filtered = list(map(filter_tokens, clean_token))\n",
    "\n",
    "\n",
    "\n",
    "    return tokens_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(x, y = 30):\n",
    "    l=len(x)\n",
    "    v=l//y\n",
    "    remainder=y\n",
    "    all_series = []\n",
    "    for loops in range(v+1):\n",
    "        new_elem = []\n",
    "        if loops > (v - 1):\n",
    "            remainder = l%y\n",
    "        if remainder > 0:\n",
    "            for i in range(remainder):\n",
    "                temp = (y * (loops)) + i\n",
    "                new_elem.extend(x[temp])\n",
    "            all_series.append(new_elem)\n",
    "    return pd.Series(all_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_it_df(item,title,author):\n",
    "    df = pd.DataFrame()\n",
    "    df['txt']= chunk(read_it(item))\n",
    "    df['title']= title\n",
    "    df['author'] = author\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "bell = make_it_df(\"/Users/andrewargaez/Author_Classifier/WBT.txt\",'For Whom the Bell Tolls','Ernest Hemmingway')\n",
    "kar = make_it_df(\"/Users/andrewargaez/Author_Classifier/karmaz.txt\", \"The Brothers Karmazov\", \"Fyodor Dostoevsky\")\n",
    "gg = make_it_df(\"/Users/andrewargaez/Author_Classifier/GG.txt\", \"The Great Gatsby\", \"F. Scott Fitzgerald\")\n",
    "pp = make_it_df(\"/Users/andrewargaez/Author_Classifier/GG.txt\", \"Pride and Prejudice\", \"Jane Austen\")\n",
    "cp = make_it_df(\"/Users/andrewargaez/Author_Classifier/CP.txt\", \"Crime and Punishment\", \"Fyodor Dostoevsky\")\n",
    "fta = make_it_df(\"/Users/andrewargaez/Author_Classifier/FTA.txt\", \"A Farewell to Arms\", \"Ernest Hemingway\")\n",
    "em = make_it_df(\"/Users/andrewargaez/Author_Classifier/emma.txt\", \"Emma\", \"Jane Austen\")\n",
    "al= make_it_df(\"/Users/andrewargaez/Author_Classifier/alice.txt\", \"Alice in Woderland\", \"Lewis Carrol\")\n",
    "drac= make_it_df(\"/Users/andrewargaez/Author_Classifier/drac.txt\", \"Dracula\", \"Bram Stoker\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df =pd.concat([bell, kar,cp,fta, gg, pp,em,al,drac],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeaky_clean(new_df):\n",
    "    others = '“,”,’,—,_,.,——'\n",
    "    vals = list(new_df['txt'].values)\n",
    "    arr=[]\n",
    "\n",
    "    for _sent in vals:\n",
    "        sent=[]\n",
    "        for word in _sent:\n",
    "            for char in others:\n",
    "                word = word.replace(char,'')\n",
    "            sent.append(word)      \n",
    "        arr.append(str(sent))\n",
    "    return pd.Series(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['txt']= squeaky_clean(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(item):\n",
    "    data=item.txt\n",
    "    labels = item.author\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(labels)\n",
    "    return np.array(data), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_naive_bayes(data, y):\n",
    "    print(\"tuning naive bayes...\")\n",
    "    kfold = KFold(5)\n",
    "    alphas = np.concatenate((np.arange(0, 0.1, 0.02), np.arange(.1, 1.3, 0.1)))\n",
    "    scores = defaultdict(list)\n",
    "    for train_index, test_index in kfold.split(data):\n",
    "        data_train, data_test = data[train_index], data[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        tfidf = TfidfVectorizer()\n",
    "        X_train = tfidf.fit_transform(data_train)\n",
    "        print(X_train.shape)\n",
    "        X_test = tfidf.transform(data_test)\n",
    "        for alpha in alphas:\n",
    "            nb = MultinomialNB(alpha=alpha)\n",
    "            nb.fit(X_train, y_train)\n",
    "            scores[alpha].append(nb.score(X_test, y_test))\n",
    "\n",
    "    print(\"alpha  score\")\n",
    "    for alpha in alphas:\n",
    "        print(\" %.2f  %f\" % (alpha, np.average(scores[alpha])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(data, y,hold_x,hold_y):\n",
    "    data_train, data_test, y_train, y_test = train_test_split(data, y)\n",
    "    \n",
    "\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_train = tfidf.fit_transform(data_train).toarray()\n",
    "    X_test = tfidf.transform(data_test).toarray()\n",
    "\n",
    "\n",
    "    print(\"running models...\")\n",
    "    models = [(\"Random Forest\", RandomForestClassifier()),\n",
    "              (\"Decision Tree\", DecisionTreeClassifier()),\n",
    "              (\"kNN\", KNeighborsClassifier()),  \n",
    "              (\"Naive Bayes\", MultinomialNB()),\n",
    "              (\"SVM\", OneVsRestClassifier(SVC())),\n",
    "              (\"Logistic\", OneVsRestClassifier(LogisticRegression()))]\n",
    "\n",
    "    print(\"%20s %7s %9s %9s\" % (\"Name\", \"Score\", \"TrainTime\", \"TestTime\"))\n",
    "\n",
    "    for name, model in models:\n",
    "        start = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        trained = time.time()\n",
    "        score = model.score(X_test, y_test)\n",
    "        tested = time.time()\n",
    "\n",
    "        # Silly stuff to make it print nicely\n",
    "        print(\"%20s   %.3f %9s %9s\" % (name, score,\n",
    "                                       str(round(trained - start, 2)),\n",
    "                                       str(round(tested - trained, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "datat, yt = get_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuning naive bayes...\n",
      "(1880, 24443)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewargaez/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1881, 25048)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewargaez/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1881, 25199)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewargaez/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1881, 24297)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewargaez/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1881, 22034)\n",
      "alpha  score\n",
      " 0.00  0.522483\n",
      " 0.02  0.528440\n",
      " 0.04  0.528015\n",
      " 0.06  0.526313\n",
      " 0.08  0.523759\n",
      " 0.10  0.521632\n",
      " 0.20  0.493121\n",
      " 0.30  0.472270\n",
      " 0.40  0.458653\n",
      " 0.50  0.454398\n",
      " 0.60  0.450568\n",
      " 0.70  0.447589\n",
      " 0.80  0.447164\n",
      " 0.90  0.446738\n",
      " 1.00  0.446313\n",
      " 1.10  0.446313\n",
      " 1.20  0.446313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewargaez/opt/anaconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running models...\n",
      "                Name   Score TrainTime  TestTime\n",
      "       Random Forest   0.889      7.95      0.08\n",
      "       Decision Tree   0.854      8.43      0.03\n",
      "                 kNN   0.942      0.02      0.28\n",
      "         Naive Bayes   0.633      0.06      0.01\n",
      "                 SVM   0.939    156.56     97.91\n",
      "            Logistic   0.920      5.95      0.09\n"
     ]
    }
   ],
   "source": [
    "data, y = get_data(new_df)\n",
    "tune_naive_bayes(data, y)\n",
    "run_models(data, y,datat,yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac68491ccfc62e6527a0fd75ffbc7adaab0e7c919453393b4b19032642ccd799"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}